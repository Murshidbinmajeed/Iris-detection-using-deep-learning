# -*- coding: utf-8 -*-
"""IrisDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oxUBCgJfn-93YKxG0psmsmTQS2Pa7azD
"""

import tensorflow as tf
import json
import numpy as np
from matplotlib import pyplot as plt
import os 
import time
import uuid
import cv2

from google.colab import drive
drive.mount('/content/drive')

def load_image(x):
    byte_img = tf.io.read_file(x)
    img = tf.io.decode_jpeg(byte_img)
    return(img)

train_images = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/train/images/*.jpg',shuffle=False)
train_images = train_images.map(load_image)
train_images = train_images.map(lambda x: tf.image.resize(x, (250,250)))
train_images = train_images.map(lambda x: x/255)

test_images = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/test/images/*.jpg',shuffle=False)
test_images = test_images.map(load_image)
test_images = test_images.map(lambda x: tf.image.resize(x, (250,250)))
test_images = test_images.map(lambda x: x/255)

val_images = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/val/images/*.jpg',shuffle=False)
val_images = val_images.map(load_image)
val_images = val_images.map(lambda x: tf.image.resize(x, (250,250)))
val_images = val_images.map(lambda x: x/255)

plt.imshow(val_images.as_numpy_iterator().next())

def load_labels(label_path):
    with open(label_path.numpy(), 'r', encoding = "utf-8") as f:
        label = json.load(f)
    return [label['keypoints']]

train_labels = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/train/labels/*.json',shuffle=False)
train_labels = train_labels.map(lambda x: tf.py_function(load_labels,[x],[tf.float16]))

test_labels = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/test/labels/*.json',shuffle=False)
test_labels = test_labels.map(lambda x: tf.py_function(load_labels,[x],[tf.float16]))

val_labels = tf.data.Dataset.list_files('/content/drive/MyDrive/aug_data/val/labels/*.json',shuffle=False)
val_labels = val_labels.map(lambda x: tf.py_function(load_labels,[x],[tf.float16]))

val_labels.as_numpy_iterator().next()

train = tf.data.Dataset.zip((train_images, train_labels))
train = train.shuffle(5000)
train = train.batch(16)
train = train.prefetch(4)

test = tf.data.Dataset.zip((test_images, test_labels))
test = test.shuffle(1300)
test = test.batch(16)
test = test.prefetch(4)

val = tf.data.Dataset.zip((val_images, val_labels))
val = val.shuffle(1000)
val = val.batch(16)
val = val.prefetch(4)

data_samples = train.as_numpy_iterator()

res = data_samples.next()

res[0].shape

fig, ax =plt.subplots(ncols=4, figsize=(20,20))
for idx in range(4):
    sample_images = res[0][idx]
    sample_cord = res[1][0][idx]
    
    cv2.circle(sample_images, tuple(np.multiply(sample_cord[:2],[250,250]).astype(int)),5,(255,0,0),-1)
    cv2.circle(sample_images, tuple(np.multiply(sample_cord[2:],[250,250]).astype(int)),5,(0,255,0),-1)
    
    ax[idx].imshow(sample_images)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, Reshape, Dropout
from tensorflow.keras.applications import ResNet152V2

model = Sequential([
    Input(shape=(250,250,3)),
    ResNet152V2(include_top=False, input_shape=(250,250,3)),
    Conv2D(512, 3, padding='same', activation='relu'),
    Conv2D(512, 3, padding='same', activation='relu'),
    Conv2D(256, 3, 2, padding='same', activation='relu'),
    Conv2D(256, 2, 2, activation='relu'),
    Dropout(0.05),
    Conv2D(4,2,2),
    Reshape((4,))
])

model.summary()

from tensorflow.keras.optimizers import Adam

optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.001,decay=0.0007)
loss = tf.keras.losses.MeanSquaredError()

model.compile(optimizer,loss)

x,y = train.as_numpy_iterator().next()

x.shape

coordinates = model.predict(x)

coordinates

hist = model.fit(train,batch_size=30 ,epochs=10,validation_data=val)

hist.history

plt.plot(hist.history['loss'], color='teal', label='loss')
plt.plot(hist.history['val_loss'], color='orange', label='val loss')
plt.suptitle('Loss')
plt.legend()
plt.show()

test_data = test.as_numpy_iterator()

test_sample = test_data.next()

test_sample[0].shape

yhat = model.predict(test_sample[0])

fig, ax =plt.subplots(ncols=4, figsize=(20,20))
for idx in range(4):
    sample_images = test_sample[0][idx]
    sample_cord = yhat[idx]
    
    cv2.circle(sample_images, tuple(np.multiply(sample_cord[:2],[250,250]).astype(int)),5,(255,0,0),-1)
    cv2.circle(sample_images, tuple(np.multiply(sample_cord[2:],[250,250]).astype(int)),5,(0,255,0),-1)
    
    ax[idx].imshow(sample_images)

from tensorflow.keras.models import load_model

model.save('/content/drive/MyDrive/eyetrackerresnet.h5')

model = load_model('/content/drive/MyDrive/eyetrackerresnet.h5')

model.predict(test_sample[0])

cap = cv2.VideoCapture(0)
while cap.isOpened():
    _ , frame = cap.read()
    
    frame = frame[50:500,50:500,:]
    rgb_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    resized = cv2.resize(rgb_img, (250,250))
    
    yhat = model.predict(np.expand_dims(resized/255,0))
    sample_coords =yhat[0,:4]
    
    cv2.circle(frame, tuple(np.multiply(sample_coord[:2],[450,450]).astype(int)), 2, (255,0,0), -1)
    cv2.circle(frame, tuple(np.multiply(sample_coord[2:],[450,450]).astype(int)), 2, (0,255,0), -1)
    
    cv2.imshow('EyeTrack',frame)
    
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break
cap.release()
cv2.destroyAllWindows()

